{"cells": [{"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "# Top Repositories for GitHub Topics\n \n"}, {"metadata": {}, "cell_type": "markdown", "source": "### Pick a website and describe your objective\n\n- Browse through different sites and pick on to scrape. Check the \"Project Ideas\" section for inspiration.\n- Identify the information you'd like to scrape from the site. Decide the format of the output CSV file.\n- Summarize your project idea and outline your strategy in a Juptyer notebook. Use the \"New\" button above.\n"}, {"metadata": {}, "cell_type": "markdown", "source": "\n#### Project Outline\n\n- We're going to scrape https://github.com/topics\n- We'll get a list of topics. For each topic, we'll get topic title, topic page URL and topic description\n- For each topic, we'll get the top 25 repositories in the topic from the topic page\n- For each repository, we'll grab the repo name, username, stars and repo URL\n- For each topic we'll create a CSV file in the following format:\n\n```\nRepo Name,Username,Stars,Repo URL\nthree.js,mrdoob,69700,https://github.com/mrdoob/three.js\nlibgdx,libgdx,18300,https://github.com/libgdx/libgdx\n```"}, {"metadata": {}, "cell_type": "markdown", "source": "## Scrape the list of topics from Github\n\n\n- use requests to downlaod the page\n- user BS4 to parse and extract information\n- convert to a Pandas dataframe\n\nLet's write a function to download the page."}, {"metadata": {}, "cell_type": "code", "source": "import requests\nfrom bs4 import BeautifulSoup\n\ndef get_topics_page():\n    # TODO - add comments\n    topics_url = 'https://github.com/topics'\n    response = requests.get(topics_url)\n    if response.status_code != 200:\n        raise Exception('Failed to load page {}'.format(topic_url))\n    doc = BeautifulSoup(response.text, 'html.parser')\n    return doc", "execution_count": 32, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Add some explanation"}, {"metadata": {}, "cell_type": "code", "source": "doc = get_topics_page()", "execution_count": 33, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Let's create some helper functions to parse information from the page.\n\nTo get topic titles, we can pick `p` tags with the `class` ...\n\n![](https://i.imgur.com/OnzIdyP.png)"}, {"metadata": {}, "cell_type": "code", "source": "def get_topic_titles(doc):\n    selection_class = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n    topic_title_tags = doc.find_all('p', {'class': selection_class})\n    topic_titles = []\n    for tag in topic_title_tags:\n        topic_titles.append(tag.text)\n    return topic_titles", "execution_count": 34, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "titles = get_topic_titles(doc)", "execution_count": 37, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "`get_topic_titles` can be used to get the list of titles"}, {"metadata": {}, "cell_type": "code", "source": "len(titles)", "execution_count": 38, "outputs": [{"output_type": "execute_result", "execution_count": 38, "data": {"text/plain": "30"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "titles[:5]", "execution_count": 39, "outputs": [{"output_type": "execute_result", "execution_count": 39, "data": {"text/plain": "['3D', 'Ajax', 'Algorithm', 'Amp', 'Android']"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Similarly we have defined functions for descriptions and URLs."}, {"metadata": {}, "cell_type": "code", "source": "def get_topic_descs(doc):\n    desc_selector = 'f5 color-fg-muted mb-0 mt-1'\n    topic_desc_tags = doc.find_all('p', {'class': desc_selector})\n    topic_descs = []\n    for tag in topic_desc_tags:\n        topic_descs.append(tag.text.strip())\n    return topic_descs\n", "execution_count": 86, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def get_topic_urls(doc):\n    topic_link_tags = doc.find_all('a', {'class': 'd-flex no-underline'})\n    topic_urls = []\n    base_url = 'https://github.com'\n    for tag in topic_link_tags:\n        topic_urls.append(base_url + tag['href'])\n    return topic_urls", "execution_count": 87, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Let's put this all together into a single function"}, {"metadata": {}, "cell_type": "code", "source": "def scrape_topics():\n    topics_url = 'https://github.com/topics'\n    response = requests.get(topics_url)\n    if response.status_code != 200:\n        raise Exception('Failed to load page {}'.format(topic_url))\n    doc = BeautifulSoup(response.text, 'html.parser')\n    topics_dict = {\n        'title': get_topic_titles(doc),\n        'description': get_topic_descs(doc),\n        'url': get_topic_urls(doc)\n    }\n    return topics_dict", "execution_count": 88, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import os\nimport pandas as pd", "execution_count": 89, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Get top 25 Repososotories form each topics"}, {"metadata": {}, "cell_type": "code", "source": "def get_topic_page(topic_url):\n    # Download the page\n    response = requests.get(topic_url)\n    # Check successful response\n    if response.status_code != 200:\n        raise Exception('Failed to load page {}'.format(topic_url))\n    # Parse using Beautiful soup\n    topic_doc = BeautifulSoup(response.text, 'html.parser')\n    return topic_doc", "execution_count": 90, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "doc = get_topic_page('https://github.com/topics/3d')", "execution_count": 91, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def get_repo_info(h1_tag, star_tag):\n    # returns all the required info about a repository\n    a_tags = h1_tag.find_all('a')\n    username = a_tags[0].text.strip()\n    repo_name = a_tags[1].text.strip()\n    repo_url =  base_url + a_tags[1]['href']\n    stars = parse_star_count(star_tag.text.strip())\n    return username, repo_name, stars, repo_url", "execution_count": 92, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def get_topic_repos(topic_doc):\n    # Get the h1 tags containing repo title, repo URL and username\n    h1_selection_class = 'f3 color-text-secondary text-normal lh-condensed'\n    repo_tags = topic_doc.find_all('h1', {'class': h1_selection_class} )\n    # Get star tags\n    star_tags = topic_doc.find_all('a', { 'class': 'social-count float-none'})\n    \n    topic_repos_dict = { 'username': [], 'repo_name': [], 'stars': [],'repo_url': []}\n\n    # Get repo info\n    for i in range(len(repo_tags)):\n        repo_info = get_repo_info(repo_tags[i], star_tags[i])\n        topic_repos_dict['username'].append(repo_info[0])\n        topic_repos_dict['repo_name'].append(repo_info[1])\n        topic_repos_dict['stars'].append(repo_info[2])\n        topic_repos_dict['repo_url'].append(repo_info[3])\n        \n    return pd.DataFrame(topic_repos_dict)", "execution_count": 93, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def scrape_topic(topic_url, path):\n    if os.path.exists(path):\n        print(\"The file {} already exists. Skipping...\".format(path))\n        return\n    topic_df = get_topic_repos(get_topic_page(topic_url))\n    topic_df.to_csv(path, index=None)", "execution_count": 94, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Putting it all together\n\n- We have a funciton to get the list of topics\n- We have a function to create a CSV file for scraped repos from a topics page\n- Let's create a function to put them together"}, {"metadata": {}, "cell_type": "code", "source": "def scrape_topics_repos():\n    print('Scraping list of topics')\n    topics_df = pd.DataFrame(scrape_topics())\n    topics_df = scrape_topics()\n    print(topics_df)\n    \n    os.makedirs('data', exist_ok=True)\n    for index, row in topics_df.iterrows():\n        print('Scraping top repositories for \"{}\"'.format(row['title']))\n        scrape_topic(row['url'], 'data/{}.csv'.format(row['title']))", "execution_count": 98, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "scrape_topics_repos()", "execution_count": 99, "outputs": [{"output_type": "stream", "text": "Scraping list of topics\n{'title': ['3D', 'Ajax', 'Algorithm', 'Amp', 'Android', 'Angular', 'Ansible', 'API', 'Arduino', 'ASP.NET', 'Atom', 'Awesome Lists', 'Amazon Web Services', 'Azure', 'Babel', 'Bash', 'Bitcoin', 'Bootstrap', 'Bot', 'C', 'Chrome', 'Chrome extension', 'Command line interface', 'Clojure', 'Code quality', 'Code review', 'Compiler', 'Continuous integration', 'COVID-19', 'C++'], 'description': ['3D modeling is the process of virtually developing the surface and structure of a 3D object.', 'Ajax is a technique for creating interactive web applications.', 'Algorithms are self-contained sequences that carry out a variety of tasks.', 'Amp is a non-blocking concurrency framework for PHP.', 'Android is an operating system built by Google designed for mobile devices.', 'Angular is an open source web application platform.', 'Ansible is a simple and powerful automation engine.', 'An API (Application Programming Interface) is a collection of protocols and subroutines for building software.', 'Arduino is an open source hardware and software company and maker community.', 'ASP.NET is a web framework for building modern web apps and services.', 'Atom is a open source text editor built with web technologies.', 'An awesome list is a list of awesome things curated by the community.', 'Amazon Web Services provides on-demand cloud computing platforms on a subscription basis.', 'Azure is a cloud computing service created by Microsoft.', 'Babel is a compiler for writing next generation JavaScript, today.', 'Bash is a shell and command language interpreter for the GNU operating system.', 'Bitcoin is a cryptocurrency developed by Satoshi Nakamoto.', 'Bootstrap is an HTML, CSS, and JavaScript framework.', 'A bot is an application that runs automated tasks over the Internet.', 'C is a general purpose programming language that first appeared in 1972.', 'Chrome is a web browser from the tech company Google.', 'Google Chrome Extensions are add-ons that allow users to customize their Chrome web browser.', 'A CLI, or command-line interface, is a console that helps users issue commands to a program.', 'Clojure is a dynamic, general-purpose programming language.', 'Automate your code review with style, quality, security, and test\u2011coverage checks when you need them.', 'Ensure your code meets quality standards and ship with confidence.', 'Compilers are software that translate higher-level programming languages to lower-level languages (e.g. machine code).', 'Automatically build and test your code as you push it upstream, preventing bugs from being deployed to production.', 'The coronavirus disease 2019 (COVID-19) is an infectious disease caused by SARS-CoV-2.', 'C++ is a general purpose and object-oriented programming language.'], 'url': ['https://github.com/topics/3d', 'https://github.com/topics/ajax', 'https://github.com/topics/algorithm', 'https://github.com/topics/amphp', 'https://github.com/topics/android', 'https://github.com/topics/angular', 'https://github.com/topics/ansible', 'https://github.com/topics/api', 'https://github.com/topics/arduino', 'https://github.com/topics/aspnet', 'https://github.com/topics/atom', 'https://github.com/topics/awesome', 'https://github.com/topics/aws', 'https://github.com/topics/azure', 'https://github.com/topics/babel', 'https://github.com/topics/bash', 'https://github.com/topics/bitcoin', 'https://github.com/topics/bootstrap', 'https://github.com/topics/bot', 'https://github.com/topics/c', 'https://github.com/topics/chrome', 'https://github.com/topics/chrome-extension', 'https://github.com/topics/cli', 'https://github.com/topics/clojure', 'https://github.com/topics/code-quality', 'https://github.com/topics/code-review', 'https://github.com/topics/compiler', 'https://github.com/topics/continuous-integration', 'https://github.com/topics/covid-19', 'https://github.com/topics/cpp']}\n", "name": "stdout"}, {"output_type": "error", "ename": "AttributeError", "evalue": "'dict' object has no attribute 'iterrows'", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)", "\u001b[0;32m<ipython-input-99-ac99c06d7fcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscrape_topics_repos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;32m<ipython-input-98-1fb51095e6ff>\u001b[0m in \u001b[0;36mscrape_topics_repos\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtopics_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Scraping top repositories for \"{}\"'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mscrape_topic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data/{}.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'iterrows'"]}]}, {"metadata": {}, "cell_type": "markdown", "source": "We can check that the CSVs were created properly"}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# read and display a CSV using Pandas", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ""}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.8", "language": "python"}, "language_info": {"name": "python", "version": "3.8.12", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}